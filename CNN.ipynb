{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0671d20-5946-403f-9ea8-8e1c3d754b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imput modul\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1795f2ef-011c-476b-a21c-eeaaaa3dc897",
   "metadata": {},
   "source": [
    "### Initialize The CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d194b5f-b34a-4d72-a68c-78b627f768ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier = Sequential() #Empty Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8dc8e35-cad9-4211-84f4-dcb25a7e293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier.add(Conv2D(32, (3,3), input_shape=(128,128,3), activation = 'relu')) #1st hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e1b1e16-4b32-4139-b41d-a6cd05875307",
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c2d821c-4a1f-4e31-9946-2c94550139a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier.add(Conv2D(64, (3,3), activation = 'relu')) #2nd hideen layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89829193-bcae-4826-847e-25884f8381f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2527060-34fb-4cea-960e-589a62d0e88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier.add(Conv2D(128,(3,3), activation = 'relu')) #3rd hodeen layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d94fe90f-4342-496a-884a-e295a37235a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier.add(Flatten()) # 1D array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9f86c2-ecfd-47f0-946e-9102eff994f3",
   "metadata": {},
   "source": [
    "### Connected layer (Hidden layer --> Output layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27feb240-76c3-4cee-b993-644c50333712",
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier.add(Dense(128, activation = 'relu')) #Connected layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d43d93e-7d2d-45bd-9648-7d4066e82677",
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier.add(Dense(3, activation = 'Softmax')) #output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53f1599a-6cb8-4419-b1d7-b6b70b98c692",
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier.compile(optimizer='adam',\n",
    "                  loss= 'categorical_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc6d092-7113-4151-baa5-76789df0715a",
   "metadata": {},
   "source": [
    "### Fitting Image with Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "529cb788-d63d-4a9f-9357-fc6fc14ab747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for filter, padding\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                      shear_range=0.2,\n",
    "                                      zoom_range=0.2,\n",
    "                                      horizontal_flip= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbe2af6d-4284-449a-8c46-21b41a418c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc40d0fb-3b5f-408b-b0c4-a31c4aef2900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2400 images belonging to 3 classes.\n",
      "Found 600 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "training_dataset = train_datagen.flow_from_directory('E:/Deep Learnig/Class/6/mm/dataset/training_set',target_size = (128,128), batch_size=32, class_mode=\"categorical\")\n",
    "\n",
    "test_datasent = test_datagen.flow_from_directory('E:/Deep Learnig/Class/6/mm/dataset/test_set',target_size = (128,128), batch_size=32, class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "411ae3a2-6ab4-48b5-89f1-1eb524a91ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "25/25 [==============================] - 9s 341ms/step - loss: 1.4601 - accuracy: 0.3275 - val_loss: 1.1005 - val_accuracy: 0.2946\n",
      "Epoch 2/5\n",
      "25/25 [==============================] - 8s 324ms/step - loss: 1.0970 - accuracy: 0.3738 - val_loss: 1.0873 - val_accuracy: 0.3527\n",
      "Epoch 3/5\n",
      "25/25 [==============================] - 8s 327ms/step - loss: 1.0869 - accuracy: 0.3812 - val_loss: 1.0655 - val_accuracy: 0.3393\n",
      "Epoch 4/5\n",
      "25/25 [==============================] - 8s 329ms/step - loss: 1.0623 - accuracy: 0.4187 - val_loss: 0.9795 - val_accuracy: 0.4688\n",
      "Epoch 5/5\n",
      "25/25 [==============================] - 8s 335ms/step - loss: 0.9687 - accuracy: 0.5163 - val_loss: 1.1557 - val_accuracy: 0.4107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2098ad0e5b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classifier.fit(training_dataset, steps_per_epoch= 800/32,epochs=5, validation_data= test_datasent, validation_steps=200/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "548e979a-0908-408e-94b3-d7798d4e02d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "target_directory = 'E:/Deep Learnig/Class/6/mm/dataset/model/'\n",
    "if not os.path.exists(target_directory):\n",
    "    os.mkdir(target_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6868708-8582-490c-b5fa-caea58b27773",
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier.save('E:/Deep Learnig/Class/6/mml/dataset/model/model.h5')\n",
    "Classifier.save_weights('E:/Deep Learnig/Class/6/mml//dataset/model/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "152fdbaf-8ab5-4339-aff2-dba3751fbf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img,img_to_array\n",
    "from keras.models import Sequential, load_model\n",
    "from PIL import Image, ImageTk\n",
    "import requests\n",
    "from tkinter import Tk, Label, Canvas, NW, Entry, Button\n",
    "from keras.preprocessing import image as image_utils\n",
    "from io import BytesIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bfc0c6ee-1122-4c1f-ad9e-c10012c127dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load Model\n",
    "image_width, image_height = 128, 128\n",
    "model_path = 'E:/Deep Learnig/Class/6/mml/dataset/model/model.h5'\n",
    "model_weight_path = 'E:/Deep Learnig/Class/6/mml//dataset/model/weights.h5'\n",
    "model = load_model (model_path)\n",
    "model.load_weights((model_weight_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ce4bbad-f942-4d15-9d13-117d0ff30b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''url = ''\n",
    "window = Tk()\n",
    "window.title('Image Classification')\n",
    "window.geometry('800x600')\n",
    "lbl = Label(window, text = 'Plesae Enter The Image Url', font = ('Halvetica', 16))\n",
    "lbl.pack()\n",
    "\n",
    "\n",
    "\n",
    "def Enter():\n",
    "    global url\n",
    "    lbl.configure()\n",
    "    url = (User_input.get())\n",
    "    print(url)\n",
    "    \n",
    "    \n",
    "    response = requests.get(url)\n",
    "    test_image = Image.open(BytesIO(response.content))\n",
    "    put_image = test_image.resize((400,400))\n",
    "    test_image = test_image.resize((128,128))\n",
    "    \n",
    "    \n",
    "    img = ImageTk.PhotoImage(put_image)\n",
    "    pic = Label(image = img)\n",
    "    pic.pack()\n",
    "    pic.image = img\n",
    "    test_image = image_utils.img_to_array(test_image)\n",
    "    test_image = np.extend_dims(test_image, axis = 0)\n",
    "    \n",
    "    \n",
    "    result = model.predict_on_batch(test_image)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if result[0][0] ==1:\n",
    "        ans = 'F'\n",
    "    elif result[0][1] ==1:\n",
    "        ans = 'P'\n",
    "    elif result[0][2] ==1:\n",
    "        ans = 'S'\n",
    "        \n",
    "        \n",
    "    out = Label(window, text ='Pradicted Result:' + ans, font =('Halentica', 16))\n",
    "    out.pack()\n",
    "    '''\n",
    "\n",
    "url = ''\n",
    "window = Tk()\n",
    "window.title(\"Image Classification\")\n",
    "window.geometry(\"800x600\")\n",
    "lbl = Label(window, text = \"Please Enter The Image Url\", font = (\"Halvetica\", 16))\n",
    "lbl.pack()\n",
    "\n",
    "\n",
    "def Enter():\n",
    "    global url\n",
    "    lbl.configure()\n",
    "    url = (User_input.get())\n",
    "    print(url)\n",
    "    \n",
    "    \n",
    "    response = requests.get(url)\n",
    "    test_image = Image.open(BytesIO(response.content))\n",
    "    put_image = test_image.resize((400, 400))\n",
    "    test_image = test_image.resize((128, 128))\n",
    "    \n",
    "    img = ImageTk.PhotoImage(put_image)\n",
    "    pic = Label(image = img)\n",
    "    pic.pack()\n",
    "    pic.image = img\n",
    "    test_image = image_utils.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    \n",
    "    result = model.predict_on_batch(test_image)\n",
    "    \n",
    "    \n",
    "    if result[0][0] == 1:\n",
    "        ans = \"French Fries\"\n",
    "    elif result[0][1] == 1:\n",
    "        ans = \"Fizza\"\n",
    "    elif result[0][2] == 1:\n",
    "        ans =  \"samosa\"\n",
    "        \n",
    "    out = Label(window, text = \"Predicted Results: \" + ans, font = (\"Halvetica\", 16))\n",
    "    \n",
    "    out.pack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852f2a85-535e-4e98-8200-18e1abb602dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/wiki/Pizza#/media/File:Eq_it-na_pizza-margherita_sep2005_sml.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\MMasum\\anaconda3\\envs\\DL\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-39-39d13906e15d>\", line 63, in Enter\n",
      "    test_image = Image.open(BytesIO(response.content))\n",
      "  File \"C:\\Users\\MMasum\\anaconda3\\envs\\DL\\lib\\site-packages\\PIL\\Image.py\", line 3023, in open\n",
      "    raise UnidentifiedImageError(\n",
      "PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x000002098D22FF90>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "User_input = Entry(width = 100)\n",
    "User_input.pack()\n",
    "button = Button(window, text = \"Detect the Image\", font = (\"Halvetica\", 16), command = Enter)\n",
    "button.pack()\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a723f06a-d6a7-41a8-b3f2-4bede12e7188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5903c7-8d3d-406f-a480-b9ce0b42d350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298661fe-495f-4218-898b-f736b3bf52cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f0a651-71da-4f1b-b72d-b0cdc8280eed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
